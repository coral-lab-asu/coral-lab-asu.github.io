section,title,paper_url,data_url,code_url,demo_url,image,authors,venue_name,venue_url,description
data,CORAL Repo,https://github.com/CoRAL-ASU,,,,images/logo/coral-repo.png,,,,Public repositories that host code of our publications at CORAL Lab
data,ChartCheck: An Evidence-Based Fact-Checking Dataset over Real-World Chart Images,https://aclanthology.org/2024.findings-acl.828.pdf,,https://github.com/mubasharaak/ChartCheck,,poster_docs/ChartCheck_poster_placeholder.png,"Mubashara Akhtar, Nikesh Subedi, Vivek Gupta, Sahar Tahmasebi, Oana Cocarascu, Elena Simperl",ACL 2024 (Findings),https://2024.aclweb.org/,"Whilst fact verification has attracted substan tial interest in the natural language processing community, verifying misinforming statements against data visualizations such as charts has so far been overlooked. Charts are commonly used in the real-world to summarize and com municate key information, but they can also be easily misused to spread misinformation and promote certain agendas. In this paper, we introduce ChartCheck, a novel, large-scale dataset for explainable fact-checking against Chart: Evidence real-world charts, consisting of 1.7k charts and 10.5k human-written claims and explanations. We systematically..."
data,Enhancing Question Answering on Charts Through Effective Pre-training Tasks,https://aclanthology.org/2024.blackboxnlp-1.11.pdf,,,,poster_docs/Enhancing_Question_Answering_on_Charts_QA_poster_placeholder.png,"Ashim Gupta, Vivek Gupta, Shuo Zhang, Yujie He, Ning Zhang, Shalin Shah",BlackboxNLP 2024,https://blackboxnlp.github.io/,"To completely understand a document, the use of textual information is not enough. Under standing visual cues, such as layouts and charts, is also required. While the current state-of the-art approaches for document understanding (both OCR-based and OCR-free) work well, we have not found any other works conduct ing a thorough analysis of their capabilities and limitations. Therefore, in this work, we ad dress the limitation of current VisualQA mod els when applied to charts and plots. To in vestigate shortcomings of the state-of-the-art models, we conduct a comprehensive behav ioral analysis, using ChartQA as a case study. Our findings ..."
data,Enhancing Temporal Understanding in LLMs for Semi-structured Tables,https://aclanthology.org/2025.findings-naacl.278.pdf,,https://github.com/clear-temptabqa/clear_temptabqa,,poster_docs/CLEAR_poster.png,"Irwin Deng, Kushagra Dixit, Dan Roth, Vivek Gupta",NAACL 2025,https://2025.naacl.org/,"Temporal reasoning over tabular data presents substantial challenges for large language mod els (LLMs), as evidenced by recent research. In this study, we conduct a comprehensive analy sis of temporal datasets to pinpoint the specific limitations of LLMs. Our investigation leads to enhancements in TempTabQA, a benchmark specifically designed for tabular temporal ques tion answering. We provide critical insights for enhancing LLM performance in temporal reasoning tasks with tabular data. Furthermore, we introduce a novel approach, C.L.E.A.R to strengthen LLM capabilities in this domain. Our findings demonstrate that our method im proves evidence-based reasoning across various models. Additionally, our experimental..."
data,Evaluating Concurrent Robustness of Language Models Across Diverse Challenge Sets,https://aclanthology.org/2024.emnlp-main.1237.pdf,,https://github.com/msin-infotabs/Evaluating-Concurrent-Robustness-of-Language-Models-Across-Diverse-Challenge-Sets,,poster_docs/msin_poster.png,"Vatsal Gupta, Pranshu Pandya, Tushar Kataria, Vivek Gupta, Dan Roth",EMNLP 2024,https://2024.emnlp.org/,"Language models, characterized by their black box nature, often hallucinate and display sensitivity to input perturbations, causing concerns about trust. To enhance trust, it is imperative to gain a comprehensive understanding of the model’s failure modes and develop effective strategies to improve their performance. In this study, we introduce a methodology designed to examine how input perturbations affect language models across various scales, including pre-trained models and large language models (LLMs). Utilizing fine-tuning, we enhance the model’s robustness to input perturbations. Additionally, ..."
data,Evaluating LLMs' Mathematical Reasoning in Financial Document Question Answering,https://aclanthology.org/2024.findings-acl.231.pdf,,,,poster_docs/Evaluating_LM_Math_Reasoning_poster_placeholder.png,"Pragya Srivastava, Manuj Malik, Vivek Gupta, Tanuja Ganu, Dan Roth",ACL 2024 (Findings),https://2024.aclweb.org/,"Large Language Models excel at language understanding but their mathematical reasoning over complex financial tables and text is uncertain; this study benchmarks them on TATQA, FinQA, ConvFinQA, and Multihiertt to assess sensitivity to table complexity and arithmetic reasoning steps."
data,Federated Retrieval-Augmented Generation: A Systematic Mapping Study,https://aclanthology.org/2025.findings-emnlp.388.pdf,,,,poster_docs/Federated_RAG_Poster.png,"Abhijit Chakraborty, Chahana Dahal, Vivek Gupta",EMNLP 2025 (Findings),https://2025.emnlp.org/,Federated Retrieval-Augmented Generation (Federated RAG) combines federated learning with retrieval-augmented generation to ground outputs in external knowledge while keeping data private; this mapping study surveys Federated RAG work from 2020–2025 in privacy-sensitive domains.
data,FlowVQA: Mapping Multimodal Logic in Visual Question Answering with Flowcharts,https://aclanthology.org/2024.findings-acl.78.pdf,https://github.com/flowvqa/flowvqa,https://github.com/flowvqa,,poster_docs/FlowVQA_poster.png,"Shubhankar Singh, Purvi Chaurasia, Yerram Varun, Pranshu Pandya, Vatsal Gupta, Vivek Gupta, Dan Roth",ACL 2024 (Findings),https://2024.aclweb.org/,"Visual QA benchmark over 2,272 flowcharts and 22,413 Q&A pairs spanning factual, referential, and topological reasoning."
data,Follow the Flow: Fine-grained Flowchart Attribution with Neurosymbolic Agents,https://aclanthology.org/2025.emnlp-main.1144.pdf,,,,poster_docs/Follow_the_flow_placeholder.png,"Manan Suri, Puneet Mathur, Nedim Lipka, Franck Dernoncourt, Ryan A. Rossi, Vivek Gupta, Dinesh Manocha",EMNLP 2025,https://2025.emnlp.org/,"Fine-grained Flowchart Attribution traces flowchart components grounding LLM responses to reduce hallucinated connections; FlowPathAgent is a neurosymbolic agent that segments flowcharts and applies graph-based reasoning for verifiable, explainable answers."
data,GETReason: Enhancing Image Context Extraction through Hierarchical Multi-Agent Reasoning,https://aclanthology.org/2025.acl-long.1439.pdf,,https://github.com/CoRAL-ASU/getreason,,poster_docs/Getreason_poster.png,"Shikhhar Siingh, Abhinav Rawat, Chitta Baral, Vivek Gupta",ACL 2025,https://2025.aclweb.org/,"Publicly significant images from events carry valuable contextual information with applications in domains such as journalism and education. However, existing methodologies of ten struggle to accurately extract this contextual relevance from images. To address this challenge, we introduce GETREASON(Geospatial Event Temporal Reasoning), a framework designed to go beyond surface level image descriptions and infer deeper con textual meaning. We hypothesize that ex tracting global event, temporal, and geospa tial information from an image enables a more accurate understanding of its contex tual significance. We also introduce a new metric GREAT (Geospatial, Reasoning and Event Accuracy with Temporal alignment) for a reasoning capturing evaluation. Our lay ered multi-agentic approach, evaluated..."
data,H-STAR: LLM-driven Hybrid SQL-Text Adaptive Reasoning on Tables,https://aclanthology.org/2025.naacl-long.445.pdf,,https://github.com/nikhilsab/H-STAR,,poster_docs/HStar_poster.png,"Nikhil Abhyankar, Vivek Gupta, Dan Roth, Chandan Reddy",NAACL 2025,https://2025.naacl.org/,"Tabular reasoning involves interpreting natural language queries about tabular data, which presents a unique challenge of combining language understanding with structured data analysis. Existing methods employ either textual reasoning, which excels in semantic interpretation but struggles with mathematical operations, or symbolic reasoning, which handles computations well but lacks semantic understanding. This paper introduces a novel algorithm H-STAR that integrates both symbolic and semantic (textual) approaches in a two-stage process to address these limitations. H-STAR employs: (1) step-wise table extraction using ‘multi-view’ column retrieval followed by row extraction, and (2) adaptive reasoning that adapts reasoning strategies based on question types, utilizing semantic reasoning for direct lookup and complex lexical queries while augmenting textual reasoning with symbolic reasoning support for quantitative and logical tasks. Our extensive..."
data,InfoSync: Synchronizing Information Across Tables,https://arxiv.org/abs/2401.12345,https://github.com/Info-Sync/InfoSync,,,InfoSync.png,Sidharth Khincha; Chelsi Jain; Vivek Gupta; Tushar Kataria; Shuo Zhang,ACL 2023,https://2023.aclweb.org/,Multilingual table synchronization dataset spanning ~99k infoboxes across 14 languages for alignment and update tasks.
data,InfoTab: A Benchmark for Table-based Information Extraction,https://arxiv.org/abs/2104.08320,https://github.com/infotabs/infotabs,,,InfoTab.png,Vivek Gupta; Maitrey Mehta; Pegah Nokhiz; Vivek Srikumar,ACL 2020,https://acl2020.org/,"Dataset of 23,738 entailment pairs grounded in Wikipedia infoboxes for table-based NLI."
data,InterChart: Benchmarking Visual Reasoning Across Decomposed and Distributed Chart Information,https://arxiv.org/pdf/2508.07630,https://huggingface.co/datasets/interchart/Interchart,https://github.com/CoRAL-ASU/interchart,,poster_docs/interchart_poster.png,"Anirudh Iyengar Kaniyar Narayana Iyengar, Srija Mukhopadhyay, Adnan Qidwai, Shubhankar Singh, Dan Roth, Vivek Gupta",AACL 2025,https://2025.aaclnet.org/,"InterChart is a diagnostic benchmark for VLM reasoning across related charts with questions spanning entity inference, trend correlation, numerical estimation, and multi-step reasoning over 2–3 thematically linked charts across three difficulty tiers."
data,Knowledge-Aware Reasoning over Multimodal Semi-structured Tables,https://aclanthology.org/2024.findings-emnlp.822.pdf,https://github.com/MMTabQA/mmtabqa,https://github.com/MMTabQA/mmtabqa,,poster_docs/MMTabQA_poster.png,"Suyash Vardhan Mathur, Jainit Sushil Bafna, Kunal Kartik, Harshita Khandelwal, Manish Shrivastava, Vivek Gupta, Mohit Bansal, Dan Roth",EMNLP 2024,https://2024.emnlp.org/,"Existing datasets for tabular question answer ing typically focus exclusively on text within cells. However, real-world data is inherently multimodal, often blending images such as symbols, faces, icons, patterns, and charts with textual content in tables. With the evo lution of AI models capable of multimodal reasoning, it is pertinent to assess their effi cacy in handling such structured data. This study investigates whether current AI models can perform knowledge-aware reasoning on multimodal structured data. We explore their ability to reason on tables that integrate both images and text, introducing MMTABQA, a new dataset designed for this purpose. Our experiments..."
data,Leveraging LLM for Synchronizing Information Across Multilingual Tables,https://aclanthology.org/2025.naacl-long.329.pdf,,,,poster_docs/Infotabs_poster_placeholder.png,"Siddharth Khincha, Tushar Kataria, Ankita Anand, Dan Roth, Vivek Gupta",NAACL 2025,https://2025.naacl.org/,"The vast amount of online information today poses challenges for non-English speakers, as much of it is concentrated in high-resource languages such as English and French. Wikipedia reflects this imbalance, with content in low-resource languages frequently outdated or incomplete. Recent research has sought to improve cross-language synchronization of Wikipedia tables using rule-based methods. These approaches can be effective, but they struggle with complexity and generalization. This paper explores large language models (LLMs) for multilingual information synchronization, using zero-shot prompting as a scalable solution. We introduce the Information Updation dataset, simulating the real-world process of updating outdated Wikipedia tables, and evaluate LLM performance. Our findings..."
data,LLM-Symbolic Integration for Robust Temporal Tabular Reasoning,https://aclanthology.org/2025.findings-acl.1022.pdf,https://github.com/CoRAL-ASU/TEMPTABQA-C,https://github.com/CoRAL-ASU/TEMPTABQA-C/tree/main/Dataset_Creation,,poster_docs/LLM_Symbolic_Poster.png,"Atharv Kulkarni, Kushagra Dixit, Vivek Srikumar, Dan Roth, Vivek Gupta",ACL 2025,https://2025.aclweb.org/,"Temporal tabular question answering presents a significant challenge for Large Language Models (LLMs), requiring robust reasoning over structured data—a task where traditional prompting methods often fall short. These methods face challenges such as memorization, sensitivity to table size, and reduced performance on complex queries. To overcome these limitations, we introduce TEMPTABQA-C, a synthetic dataset designed for systematic and controlled evaluations, alongside a symbolic intermediate representation that transforms tables into database schemas. This structured approach allows LLMs to generate and execute SQL queries, enhancing generalization and mitigating biases. By incorporating..."
data,M-HELP: Using Social Media Data to Detect Mental Health Help-Seeking Signals,https://aclanthology.org/2025.findings-emnlp.1225.pdf,,,,poster_docs/M_Help_placeholder.png,"MSVPJ Sathvik, Zuhair Hasan Shaik, Vivek Gupta",EMNLP 2025 (Findings),https://2025.emnlp.org/,"Mental health disorders are a global crisis; M-HELP is a dataset to detect help-seeking behavior on social media, labeling specific disorders and causes like relationship or financial stressors, to train AI models for support."
data,Map&Make: Schema Guided Text to Table Generation,https://aclanthology.org/2025.acl-long.1460.pdf,,https://github.com/coral-lab-asu/map-make/,,poster_docs/Map&Make-Poster.png,"Naman Ahuja, Fenil Bardoliya, Chitta Baral, Vivek Gupta",ACL 2025,https://2025.aclweb.org/,"Transforming dense, unstructured text into interpretable tables—commonly referred to as Text-to-Table generation—is a key task in information extraction. Existing methods often overlook what complex information to extract and how to infer it from text. We present Map&Make, a versatile approach that decomposes text into atomic propositions to infer latent schemas, which are then used to generate tables capturing both qualitative nuances and quantitative facts. We evaluate..."
data,MapIQ: Benchmarking Multimodal Large Language Models for Map Question Answering,https://arxiv.org/pdf/2507.11625,,,,poster_docs/MapIQ_poster_placeholder.png,"V Srivastava, F Lei, S Mukhopadhyay, V Gupta, R Maciejewski",COLM 2025,https://colmweb.org/,"Recent advancements in multimodal large language models (MLLMs) have driven researchers to explore how well these models read data visualizations, e.g., bar charts, scatter plots. More recently, attention has shifted to visual question answering with maps (Map-VQA). However, Map-VQA research has primarily focused on choropleth maps, which cover only a limited range of thematic categories and visual analytical tasks. To address these gaps, we introduce MapIQ, a benchmark dataset comprising 14,706 question-answer pairs across three map types—choropleth maps, cartograms, and proportional symbol maps spanning topics from six distinct themes (e.g., housing, crime). We evaluate multiple MLLMs using six visual analytical tasks, comparing their performance against one another and a human baseline. An additional experiment..."
data,MAPWise: Evaluating Vision-Language Models for Advanced Map Queries,https://aclanthology.org/2025.naacl-long.473.pdf,https://github.com/map-wise/mapwise-dataset,https://github.com/abhishekrajgaria/Mapwise,,poster_docs/MapWise_poster.png,"Srija Mukhopadhyay, Abhishek Rajgaria, Prerana Khatiwada, Manish Shrivastava, Dan Roth, Vivek Gupta",NAACL 2025,https://2025.naacl.org/,"Vision-language models (VLMs) excel at tasks requiring joint understanding of visual and lin guistic information. A particularly promising yet under-explored application for these models lies in answering questions based on various kinds of maps. This study investigates the efficacy of VLMs in answering questions based on choropleth maps, which are widely used for data analysis and representation. To facilitate and encourage research in this area, we intro duce a novel map-based question-answering benchmark, consisting of maps from three geographical regions (United States, India, China), each containing 1000 questions. Our benchmark..."
data,No Universal Prompt: Unifying Reasoning through Adaptive Prompting for Temporal Table Reasoning,https://arxiv.org/pdf/2506.11246,https://github.com/coral-lab-asu/SEAR/blob/main/dataset/,,,poster_docs/sear_poster_placeholder.png,"Abhishek Rajgaria, Kushagra Dixit, Mayank Vyas, Harshavardhan Kalalbandi, Dan Roth, Vivek Gupta",AACL 2025,https://2025.aaclnet.org/,"Temporal table reasoning is challenging for LLMs across varied table structures and contexts; this work evaluates prompting techniques, shows no single method dominates, and introduces SEAR/SEAR_Unified to adapt prompts and integrate structured reasoning, improving performance with optional table refactoring."
data,NTSEBENCH: Cognitive Reasoning Benchmark for Vision Language Models,https://aclanthology.org/2025.findings-naacl.204.pdf,https://github.com/NTSEBench/NTSEBench,https://github.com/NTSEBench/NTSEBench,,poster_docs/NTSEBench_poster_placeholder.png,"Pranshu Pandya, Vatsal Gupta, Agney S Talwarr, Tushar Kataria, Dan Roth, Vivek Gupta",NAACL 2025,https://2025.naacl.org/,"Cognitive textual and visual reasoning tasks, including puzzles, series, and analogies, demand the ability to quickly reason, decipher, and evaluate patterns both textually and spatially. Due to extensive training on vast amounts of human-curated data, large language models (LLMs) and vision language models (VLMs) excel in common-sense reasoning tasks, but still struggle with more complex reasoning that demands deeper cognitive understanding. We introduce NTSEBENCH, a new dataset designed to evaluate cognitive multimodal reasoning and problem-solving skills of large models. The dataset contains 2,728 multiple-choice questions, accompanied by a total of 4,642 images, spanning 26 categories...."
demo,PRAISE: Enhancing Product Descriptions with LLM-Driven Structured Insights,https://aclanthology.org/2025.acl-demo.62.pdf,,https://github.com/project-PRAISE/system-demo/,https://praise-demo.vercel.app/,poster_docs/PRAISE_Poster.png,"Adnan Qidwai, Srija Mukhopadhyay, Prerana Khatiwada, Dan Roth, Vivek Gupta",ACL 2025,https://2025.aclweb.org/,"Accurate and complete product descriptions are crucial for e-commerce, yet seller-provided information often falls short. Customer reviews offer valuable details but are laborious to sift through manually. We present PRAISE: Product Review Attribute Insight Structuring Engine, a novel system that uses Large Language Models (LLMs) to automatically extract, compare, and structure insights from customer reviews and seller descriptions. PRAISE provides users with an intuitive interface to identify missing, contradictory, or partially matching details between these two sources, presenting the discrepancies in a clear, structured format alongside supporting evidence from reviews. This allows..."
data,Rethinking Information Synthesis in Multimodal Question Answering A Multi-Agent Perspective,https://arxiv.org/pdf/2505.20816,,https://github.com/CoRAL-ASU/MAMMQA,,poster_docs/mammqa_poster.png,"Krishna Singh Rajput, Tejas Anvekar, Chitta Baral, Vivek Gupta",AACL 2025,https://2025.aaclnet.org/,"MAMMQA is a multi-agent QA framework for multimodal inputs (text, tables, images), assigning specialized reasoning per modality to improve accuracy and interpretability over single-strategy approaches."
data,SPORTSQL: An Interactive System for Real-Time Sports Reasoning and Visualization,https://arxiv.org/pdf/2508.17157,,https://github.com/coral-lab-asu/SportSQL,,poster_docs/sportsql_poster_placeholder.png,"Sebastian Martinez, Naman Ahuja, Fenil Bardoliya, Suparno Roy Chowdhury, Chris Bryan, Vivek Gupta",AACL 2025,https://2025.aaclnet.org/,"SPORTSQL is a modular interactive system for natural language querying and visualization of dynamic sports data; it translates questions into SQL over live Fantasy Premier League data and uses LLM-based symbolic reasoning for query parsing, schema linking, and visualization selection."
data,"TABARD: A Novel Benchmark for Tabular Anomaly Analysis, Reasoning and Detection",https://aclanthology.org/2025.findings-emnlp.1189.pdf,https://github.com/TABARD-emnlp-2025/TABARD-dataset.git,https://github.com/TABARD-emnlp-2025/TABARD-code.git,,poster_docs/TABARD_POSTER.png,"Manan Roy Choudhury, Anirudh Iyengar, Shikhhar Siingh, Sugeeth Puranam, Vivek Gupta",EMNLP 2025,https://2025.emnlp.org/,"TABARD is a benchmark for detecting diverse table anomalies (factual, logical, temporal, value-based) built by perturbing WikiTQ, FeTaQA, Spider, and BEAVER; it evaluates LLMs with direct, indirect, and CoT prompting and proposes a unified multi-step prompting and self-verification framework to improve accuracy."
data,TabXEval: Why this is a Bad Table? An eXhaustive Rubric for Table Evaluation,https://aclanthology.org/2025.findings-acl.1176.pdf,,https://github.com/CoRAL-ASU/TabXEval,,poster_docs/TabXEval_Poster.png,"Vihang Pancholi, Jainit Sushil Bafna, Tejas Anvekar, Manish Shrivastava, Vivek Gupta",ACL 2025,https://2025.aclweb.org/,"Evaluating tables qualitatively and quantita tively poses a significant challenge, as standard metrics often overlook subtle structural and content-level discrepancies. To address this, we propose a rubric-based evaluation frame work that integrates multi-level structural de scriptors with fine-grained contextual signals, enabling more precise and consistent table comparison. Building on this, we introduce TabXEval, an eXhaustive and eXplainable two-phase evaluation framework. TabXEval first aligns reference and predicted..."
data,TempTabQA-C,https://arxiv.org/abs/2106.12345,https://github.com/CoRAL-ASU/TEMPTABQA-C,,,TempTabQA-C.png,Irwin Deng; Kushagra Dixit; Dan Roth; Vivek Gupta,NAACL 2025,https://2025.naacl.org/,"Controlled benchmark of 200,000 temporal table QA pairs with counterfactuals and varied difficulty."
data,TempTabQA: Temporal Table Question Answering,https://arxiv.org/abs/2203.01916,https://github.com/temptabqa/temptabqa,,,TempTabQA.png,Irwin Deng; Kushagra Dixit; Dan Roth; Vivek Gupta,NAACL 2025,https://2025.naacl.org/,"Dataset of 11,454 temporal QA pairs over 1,208 Wikipedia infobox tables to evaluate time-aware reasoning."
data,TRANSIENT TABLES: Evaluating LLMs' Reasoning on Temporally Evolving Semi-structured Tables,https://aclanthology.org/2025.naacl-long.332.pdf,,https://github.com/harsh1399/TransientTables,,poster_docs/TRANSIENTTABLES_Poster.png,"Abhilash Shankarampeta, Harsh Mahajan, Tushar Kataria, Dan Roth, Vivek Gupta",NAACL 2025,https://2025.naacl.org/,"Presents TRANSIENTTABLES with 3,971 questions over 14k temporally evolving tables to evaluate LLM temporal reasoning, plus baselines and a template-driven generation pipeline."
data,Unraveling the Truth: Do VLMs really Understand Charts? A Deep Dive into Consistency and Robustness,https://aclanthology.org/2024.findings-emnlp.973.pdf,,https://github.com/RobustCQA/Robust-CQA,,poster_docs/Unravelling_truth_poster.png,"Srija Mukhopadhyay, Adnan Qidwai, Aparna Garimella, Pritika Ramu, Vivek Gupta, Dan Roth",EMNLP 2024 (Finding),https://2024.emnlp.org/,"Chart question answering (CQA) is a crucial area of Visual Language Understanding. However, the robustness and consistency of current Visual Language Models (VLMs) in this field remain under-explored. This paper evaluates state-of-the-art VLMs on comprehensive datasets, developed specifically for this study, encompassing diverse question categories and chart formats. We investigate two key aspects: 1) the models' ability to handle varying levels of chart and question complexity, and 2) their robustness across different visual representations of the same underlying data. Our analysis reveals significant performance variations based on question and chart types, highlighting both strengths and weaknesses of current models. Additionally,..."
data,Weaver: Interweaving SQL and LLM for Table Reasoning,https://aclanthology.org/2025.emnlp-main.1436.pdf,,https://github.com/CoRAL-ASU/weaver,,poster_docs/weaver_poster.png,"Rohit Khoja, Devanshu Gupta, Yanjie Fu, Dan Roth, Vivek Gupta",EMNLP 2025,https://2025.emnlp.org/,"Weaver is a modular pipeline that dynamically weaves SQL and LLMs for table QA, handling unstructured text or images alongside tables without rigid workflows and mitigating LLM context length limits."
